"""diff_worker.py – Flow-1 HTML-diff generator
================================================
This tiny Python script stays running inside the *diff_worker* Docker
container.  All it really does is:

1.  Open a **persistent** connection to Redis using the URL provided in
    the `REDIS_URL` environment variable (defaults to
    `redis://localhost:6379` when you run the worker outside Docker).
2.  Wait (block) for new entries in the *`script.turn.updated`* Redis
    Stream.  Each entry is published by the Node.js API-server whenever
    an editor saves a new version of a turn.
3.  Generate a human-readable **HTML diff** of the text change.  For
    now we use Python's built-in `difflib.HtmlDiff`, which is good
    enough for the MVP.  You can swap it later for a fancier library
    like *diff-match-patch* without changing the surrounding code.
4.  Push a brand-new entry onto the *`script.turn.diff_reported`* Stream
    so downstream tools (e.g. a Slack bot or metrics dashboard) can see
    exactly what changed.

The code purposefully keeps the algorithm *very* simple and has lots of
inline comments so anybody—even those unfamiliar with Redis Streams—can
follow along.

Example (run outside Docker):
-----------------------------
```bash
export REDIS_URL=redis://localhost:6379
python apps/py-ai-service/diff_worker.py
```
The script will sit quietly until you POST an update via the PATCH
`/turn/:id` endpoint, at which point you'll see log lines in your
terminal confirming that the diff was created and published.
"""

from __future__ import annotations

import difflib
import json
import logging
import os
import time
from typing import Dict, List, Tuple

from redis import Redis
from neo4j import GraphDatabase

# ---------------------------------------------------------------------------
# Configuration (all overridable via env vars)
# ---------------------------------------------------------------------------

REDIS_URL: str = os.getenv("REDIS_URL", "redis://localhost:6379")
STREAM_IN: str = os.getenv("REDIS_STREAM_IN", "script.turn.updated")
STREAM_OUT: str = os.getenv("REDIS_STREAM_OUT", "script.turn.diff_reported")
CONSUMER_GROUP: str = "diff_worker"  # You can run many workers; each one will share the workload.
CONSUMER_NAME: str = os.getenv("HOSTNAME", "diff_worker_1")  # Helpful for debugging in `XINFO CONSUMERS`.
NEO4J_URI: str = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USER: str = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD: str = os.getenv("NEO4J_PASSWORD", "test12345")
POLL_TIMEOUT_MS: int = 5000  # Block for 5 seconds at a time (0 => infinite).

# ---------------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------------

def _ensure_consumer_group(client: Redis) -> None:
    """Create the consumer group if it doesn't exist already.

    We use `MKSTREAM` so the command succeeds even when the stream has
    never received a message.
    """

    try:
        client.xgroup_create(name=STREAM_IN, groupname=CONSUMER_GROUP, id="0-0", mkstream=True)
    except Exception as err:  # pragma: no cover – redis-py raises its own subclass
        if "BUSYGROUP" in str(err):
            # The group is already present, which is totally fine during restarts.
            return
        raise  # Unknown error → crash fast so Docker can restart us.


def _compute_html_diff(old: str, new: str) -> str:
    """Return a table-based HTML diff between two text blocks.

    Parameters
    ----------
    old : str
        The *previous* version of the text.
    new : str
        The *updated* version of the text.

    Returns
    -------
    str
        A `<table>` element generated by `difflib.HtmlDiff` that visually
        highlights insertions/deletions.  Safe to embed directly into a
        `<iframe>` or send in an email.
    """

    differ = difflib.HtmlDiff(tabsize=2, wrapcolumn=80)
    return differ.make_table(old.splitlines(), new.splitlines(), context=True)


def _process_message(client: Redis, _id: str, fields: Dict[str, str]) -> None:
    """Handle one entry from the *script.turn.updated* stream.

    Notes
    -----
    The upstream API currently publishes fields:
    `id, parent_id, persona_id, editor, ts, text, commit_message?`

    For the MVP we only care about the text, but we *do* pass through
    the identifying metadata untouched so consumers can match the diff
    up to the correct turn.
    """

    try:
        # ------------------------------------------------------------------
        # Step 1 – Fetch the *previous* turn's text from Neo4j.
        # ------------------------------------------------------------------
        parent_id = fields.get("parent_id")
        previous_text = ""
        if parent_id:
            try:
                with _neo4j_driver.session() as session:  # type: ignore[attr-defined]
                    result = session.run(
                        "MATCH (t:Turn {id: $id}) RETURN t.text AS text LIMIT 1",
                        id=parent_id,
                    )
                    record = result.single()
                    previous_text = record["text"] if record and record["text"] else ""
            except Exception:
                # We deliberately swallow Neo4j errors here so the worker still
                # emits *something* rather than failing the whole message.
                logging.exception("Failed to load parent turn %s from Neo4j – diff will compare against empty string", parent_id)

        current_text = fields.get("text", "")

        diff_html = _compute_html_diff(previous_text, current_text)

        out_fields = {
            # Pass-through identifiers so downstream services have context
            "id": fields.get("id"),
            "parent_id": fields.get("parent_id"),
            "persona_id": fields.get("persona_id"),
            # Worker-specific payload
            "diff_html": diff_html,
            "grade": "todo",  # Placeholder – a later milestone will add automated grading.
        }

        client.xadd(STREAM_OUT, out_fields)
        client.xack(STREAM_IN, CONSUMER_GROUP, _id)

        logging.info("Diff published for turn %s (persona %s)", fields.get("id"), fields.get("persona_id"))

    except Exception:  # pragma: no cover – we *never* want to crash the loop on a single failure.
        logging.exception("Failed to process stream entry – keeping the message pending for retry")


# ---------------------------------------------------------------------------
# Main loop
# ---------------------------------------------------------------------------

def main() -> None:
    """Entry-point when Docker runs `python diff_worker.py`."""

    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")

    # Single Redis connection (decoded to str) – reused for the whole process.
    client = Redis.from_url(REDIS_URL, decode_responses=True)
    logging.info("Connected to Redis at %s", REDIS_URL)

    # Neo4j driver – we *also* create once and reuse; the driver handles its
    # own connection pool internally so this is the recommended pattern.
    global _neo4j_driver  # Declare global so helper function can access it.
    _neo4j_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
    try:
        _neo4j_driver.verify_connectivity()
        logging.info("Connected to Neo4j at %s", NEO4J_URI)
    except Exception:
        logging.exception("Unable to connect to Neo4j – the worker will still run but diffs will lack previous text")

    _ensure_consumer_group(client)

    while True:
        # Read 1 message at a time so we don't hog the entire batch when multiple workers run.
        response: List[Tuple[str, List[Tuple[str, Dict[str, str]]]]] = client.xreadgroup(
            groupname=CONSUMER_GROUP,
            consumername=CONSUMER_NAME,
            streams={STREAM_IN: ">"},
            count=1,
            block=POLL_TIMEOUT_MS,
        )

        if not response:
            # Timeouts are normal – just loop and block again.
            continue

        # The redis-py type stubs are incomplete; hence the loose typing.
        for _stream, messages in response:
            for msg_id, msg_fields in messages:
                _process_message(client, msg_id, msg_fields)

        # Tiny sleep keeps CPU usage near-zero when messages are sparse.
        time.sleep(0.01)


if __name__ == "__main__":
    main()

# Neo4j driver is created in `main()` and stored in this module-level variable
# so helper functions can reuse it without passing around a reference.
_neo4j_driver = None  # type: ignore 